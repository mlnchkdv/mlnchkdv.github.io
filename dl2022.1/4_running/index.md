# [⬅Глубокое обучение 2022.1](../index.html)

## Разработка и запуск нейронных сетей

[TOC]



### Преодобработка данных

Нейронным сетям для обучения требуется обучающая выборка. Это главный минус, т.к. обычно нужно собрать много данных. 

К примеру, если мы пишем распознавание лиц в классическом машинном обучении, то нам не нужна база из фотографий – достаточно нескольких фото, по которым человек сам составит алгоритм определения лица, или даже сделает это по памяти, вообще без фото.

В случае с нейронными сетями ситуация иная – нужна большая база того, на чем мы хотим обучить нейронную сеть. При этом важно не только собрать базу, но и определенным образом её предобработать.

Поэтому очень часто сбор базы производится в том числе фрилансерами или крупными бизнесами (классический пример - сбор данных компанией Google для того, чтобы показывать нам капчи).

#### Базовые источники

- [Google Dataset Search](https://toolbox.google.com/datasetsearch). Dataset Search позволяет по ключевому слову искать датасеты по всей Сети.
- [Kaggle](https://www.kaggle.com/). Площадка для соревнований по машинному обучению с множеством интересных датасетов. В [списке датасетов](https://www.kaggle.com/datasets) можно найти разные нишевые экземпляры — от [оценок рамена](https://www.kaggle.com/datasets) до [баскетбольных данных NCAA ](https://www.kaggle.com/ncaa/ncaa-basketball) и [базы лицензий на домашних животных в Сиэтле](https://www.kaggle.com/aaronschlegel/seattle-pet-licenses).
- [UCI Machine Learning Repository](http://mlr.cs.umass.edu/ml/). Один из старейших источников датасетов в Сети и первое место, куда стоит заглянуть в поиске интересных датасетов. Хотя они добавляются пользователями и потому имеют различную степень «чистоты», большинство из них очищены. Данные можно скачивать сразу, без регистрации.
- [VisualData](https://www.visualdata.io/). Датасеты для компьютерного зрения, разбитые по категориям. Доступен поиск.
- [Find Datasets | CMU Libraries](https://guides.library.cmu.edu/machine-learning/datasets). Коллекция датасетов, предоставленная университетом Карнеги Меллон.

#### Государственные датасеты

- [Data.gov](https://www.data.gov/). Здесь можно найти данные от разных государственных учреждений США. Они варьируются от государственных бюджетов до школьных оценок.
- [Food Environment Atlas](https://catalog.data.gov/dataset/food-environment-atlas-f4a22). Содержит данные о том, как различные факторы (близость магазинов/ресторанов, цены на продукты и тому подобное) влияют на выбор продуктов и качество питания в США.
- [School system finances](https://catalog.data.gov/dataset/annual-survey-of-school-system-finances). Данные о финансах школьных систем в США.
- [Chronic disease data](https://www.cdc.gov/chronicdisease/data/index.htm). Данные о показателях хронических заболеваний на территории США.
- [The US National Center for Education Statistics](https://nces.ed.gov/). Данные об образовательных учреждениях и образовательной демографии в США и во всём мире.
- [The UK Data Service](https://www.ukdataservice.ac.uk/). Крупнейшая в Великобритании коллекция социальных, экономических и демографических данных.
- [Data USA](https://datausa.io/). Исчерпывающая визуализация общедоступных данных США.

#### Данные о жилье

- [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). Содержит информацию о жилье в Бостоне, собранную бюро переписи населения США. Она была получена из [архива StatLib](http://lib.stat.cmu.edu/datasets/boston) и широко использовалась в литературе для оценки алгоритмов.

#### Экономика и финансы

- [Quandl](https://www.quandl.com/). Хороший источник экономических и финансовых данных — полезен при построении моделей для прогнозирования экономических показателей или цен на акции.
- [World Bank Open Data](https://data.worldbank.org/). Наборы данных, охватывающих демографическую ситуацию, огромное количество экономических показателей и индикаторов развития со всего мира.
- [IMF Data](https://www.imf.org/en/Data). Международный валютный фонд публикует данные о международных финансах, показателях долга, валютных резервах, инвестициях и ценах на сырьевые товары.
- [Financial Times Market Data](https://markets.ft.com/data/). Актуальная информация о финансовых рынках со всего мира, которая включает индексы цен на акции, товары и валюту.
- [Google Trends](https://trends.google.com/trends/?q=google&ctab=0&geo=all&date=all&sort=0). Изучайте и анализируйте данные о поисковой активности в Интернете и трендах по всему миру.
- [American Economic Association (AEA)](https://www.aeaweb.org/resources/data/us-macro-regional). Хороший источник данных о макроэкономике США.

#### Компьютерное зрение

- [xView](http://xviewdataset.org/#dataset). Один из самых больших общедоступных наборов воздушных снимков земли. Он содержит изображения различных сцен со всего мира, аннотированных с помощью ограничительных рамок.
- [Labelme](http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php). Большой датасет аннотированных изображений.
- [ImageNet](http://image-net.org/). Датасет изображений для новых алгоритмов, организованный в соответствии с иерархией WordNet, в которой сотни и тысячи изображений представляют каждый узел иерархии.
- [LSUN](https://www.yf.io/p/lsun). Датасет изображений, разбитых по сценам и категориям с частичной разметкой данных.
- [MS COCO](http://cocodataset.org/#home). Крупномасштабный датасет для обнаружения и сегментации объектов.
- [COIL100](https://www.kaggle.com/jessicali9530/coil100). 100 разных объектов, изображённых под каждым углом в круговом обороте.
- [Visual Genome](http://visualgenome.org/). Датасет с ~100 тыс. подробно аннотированных изображений.
- [Google’s Open Images](https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html). Коллекция из 9 миллионов URL-адресов к изображениям, «которые были помечены метками, охватывающими более 6000 категорий» под лицензией Creative Commons.
- [Labelled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/). Набор из 13 000 размеченных изображений лиц людей для использования приложений, которые предполагают использование технологии распознавания лиц.
- [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). Содержит 20 580 изображений из 120 пород собак.
- [Indoor Scene Recognition](http://web.mit.edu/torralba/www/indoor.html). Датасет для распознавания интерьера зданий. Содержит 15 620 изображений и 67 категорий.

#### Анализ тональности текста

- [Multidomain sentiment analysis dataset](http://www.cs.jhu.edu/~mdredze/datasets/sentiment/). Немного устаревший датасет, который содержит отзывы на товары с Amazon.
- [IMDB reviews](http://ai.stanford.edu/~amaas/data/sentiment/). Староватый, относительной небольшой (25 000 отзывов к фильмам) датасет для бинарного анализа тональности.
- [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/code.html). Стэнфордский датасет для анализа тональности.
- [Sentiment140](http://help.sentiment140.com/for-students/). Популярный датасет с 160 000 твитов с удалёнными смайликами.
- [Twitter US Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment). Набор данных из Twitter об авиакомпаниях США, датируемый февралём 2015 года, разделённый на положительные, негативные и нейтральные твиты.

#### Обработка естественного языка

- [HotspotQA Dataset](https://hotpotqa.github.io/). Датасет с вопросами-ответами, позволяющий создавать системы для ответов на вопросы более понятным способом.
- [Enron Dataset](https://www.cs.cmu.edu/~./enron/). Данные электронной почты от высшего руководства Enron.
- [Amazon Reviews](https://snap.stanford.edu/data/web-Amazon.html). Содержит около 35 млн отзывов с Amazon за 18 лет. Данные включают информацию о продукте и пользователе, оценки и сам текст отзыва.
- [Google Books Ngrams](https://aws.amazon.com/ru/datasets/google-books-ngrams/). Коллекция слов из Google Книги.
- [Blogger Corpus](http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm). Коллекция из 681 288 постов с Blogger. Каждый блог содержит как минимум 200 вхождений часто используемых английских слов.
- [Wikipedia Links data](https://code.google.com/archive/p/wiki-links/downloads). Датасет, состоящий из веб-страниц, которые удовлетворяют следующим двум условиям: каждая из них содержит хотя бы одну ссылку на Википедию и текст её якоря совпадает или похож на заголовок целевой страницы.
- [Gutenberg eBooks List](https://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs). Аннотированный список электронных книг проекта «Гутенберг».
- [Hansards text chunks of Canadian Parliament](https://www.isi.edu/natural-language/download/hansard/). Датасет с 1.3 миллионами пар текстовых файлов, записанных с дебатов 36-го Канадского Парламента.
- [Jeopardy](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). Архив с более чем 200 000 вопросов с телевикторины Jeopardy.
- [Rotten Tomatoes Reviews](https://drive.google.com/file/d/1w1TsJB-gmIkZ28d1j7sf1sqcPmHXw352/view). Архив из более чем 480 000 рецензий с Rotten Tomatoes.
- [SMS Spam Collection in English](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). Датасет, состоящий из 5574 спам-смс на английском.
- [Yelp Reviews](https://www.yelp.com/dataset). Датасет от Yelp, содержащий более 5 млн отзывов.
- [UCI’s Spambase](https://archive.ics.uci.edu/ml/datasets/Spambase). Большой датасет спам-писем.

#### Автопилоты

- [Berkeley DeepDrive BDD100k](https://bdd-data.berkeley.edu/). На данный момент это самый большой датасет для автопилотов. Он содержит более 100 000 видео с более чем 1100 часами записей вождения в разное время дня и в различных погодных условиях.
- [Baidu Apolloscapes](http://apolloscape.auto/). Большой датасет для распознавания 26 семантически разных объектов вроде машин, велосипедов, пешеходов, зданий, уличных фонарей и т. д.
- [Comma.ai](https://archive.org/details/comma-dataset). Более семи часов езды по шоссе. Датасет включает информацию о скорости машины, ускорении, угле поворота руля и GPS-координатах.
- [Oxford’s Robotic Car](https://robotcar-dataset.robots.ox.ac.uk/). Более ста повторений одного маршрута по Оксфорду, заснятого в течение года. В датасет попали разные комбинации погодных условий, трафика и пешеходов, а также более длительные изменения вроде дорожных работ.
- [Cityscape Dataset](https://www.cityscapes-dataset.com/). Большой датасет, содержащий записи ста уличных сцен в 50 городах.
- [KUL Belgium Traffic Sign Dataset](http://www.vision.ee.ethz.ch/~timofter/traffic_signs/). Более 10 000 аннотаций тысяч разных светофоров в Бельгии.
- [LISA. Laboratory for Intelligent & Safe Automobiles, UC San Diego Datasets](http://cvrr.ucsd.edu/LISA/datasets.html). Датасет с дорожными знаками, светофорами, распознанными средствами передвижения и траекториями движения.
- [Bosch Small Traffic Light Dataset](https://hci.iwr.uni-heidelberg.de/node/6132). Датасет с 24 000 аннотированных светофоров.
- [LaRa Traffic Light Recognition](http://www.lara.prd.fr/benchmarks/trafficlightsrecognition). Ещё один датасет для распознавания светофоров.
- [WPI datasets](http://computing.wpi.edu/dataset.html). Датасет для распознавания светофоров, пешеходов и дорожной разметки.

#### Медицинские данные

- [MIMIC-III](https://mimic.physionet.org/). Датасет с обезличенными данными о состоянии здоровья ~40 000 пациентов, находящихся на интенсивной терапии. Он включает демографические данные, показатели жизнедеятельности, лабораторные анализы, лекарства и многое другое.



### Проектирование нейронных сетей

Можно не быть экспертом в какой-либо предметной области, но, будучи экспертом в нейронных сетях решить практически любую задачу.

Да, экспертность, безусловно влияет в плюс, т.к. мы можем лучше предобработать данные и, возможно, быстрее решить задачу, но в целом это не является критическим фактором.

Если в классическом машинном обучении не являясь экспертом в предметной области (например, атомная энергетика, машиностроение, геологические процессы и т.п.) мы вообще не сможем решить задачу, то здесь это вполне реально.



### Фреймворки глубокого обучения

Что такое фреймворки и библиотеки? Это набор функций, которые позволяют собирать и обучать нейронную сеть без необходимости глубокого понимания математической базу, лежащей в основе этих процессов.

Так, на настоящее время наиболее известными являются следующие библиотеки:

- TensorFlow (Google)
- CNTK (Microsoft)
- Theano (Монреальский институт алгоритмов обучения (MILA))
- Pytorch (Facebook)

Фреймворк Keras - также был разработан Google, и именно с ней мы будем больше всего работать. Мы также немного затронем TensorFlow и Pytorch, но уже ближе к окончанию обучения.

В иерархии это выглядит следующим образом, начиная от самых низкоуровневых инструментов:

![](.\images\42.webp)

- Сама видеокарта (GPU).
- CUDA (программно-аппаратная архитектура параллельных вычислений, которая позволяет существенно увеличить вычислительную производительность благодаря использованию графических процессоров фирмы Nvidia).
- cuDNN (библиотека, содержащая оптимизированные для GPU реализации сверточных и рекуррентных сетей, различных функций активации, алгоритма обратного распространения ошибки и т.п., что позволяет обучать нейронные сети на GPU в несколько раз быстрее, чем просто CUDA).
- TensorFlow, CNTK, Theano (надстройки над cuDNN).

Keras же, в свою очередь, использует в качестве бэкенда TensorFlow и некоторые другие библиотеками, позволяя нам пользоваться уже готовым кодом, написанными именно для создания нейронных сетей.

Еще один важный момент, который нужно отметить - это вопрос о том, как со всем этим работает Python. Многие говорят, что он работает медленно.

Да, это так, но Keras генерирует не код Python, Keras генерирует код С++, и именно он уже используется непосредственно для работы нейронной сети, поэтому все работает быстро.



### Запуск нейронной сети в облаке - на примере распознания рукописных цифр

Для облачного запуска воспользуемся сервисом [*Google Colaboratory*](https://neural-university.ru/vocabulary-neural-netwoks#rec118268861). В облаке установлен интерпретатор *Python*, различные библиотеки машинного обучения, плюс к этому, выделяется вычислительные ресурсы (*GPU Tesla K80*), которые можно использовать для обучения нейронных сетей.

Запускать *Google Colaboratory* рекомендуется под *Google Chrome*, и при первой попытке открыть ноутбук (так называется любой документ в *Google Colaboratory*) вам будет предложено установить в браузер приложение *Colaboratory*, чтобы в будущем оно автоматически "подхватывало" файлы такого типа или его можно установить по [ссылке](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo?hl=ru&utm_source=chrome-ntp-launcher).



#### Интерфейс *Google Colaboratory*

Первым делом необходимо подключиться к вычислительным ресурсам, которые нам предоставляет *Google*. Для этого в верхней правой части окна нажмите на *Connect - connect to hosted runtime*.

![](.\images\01_colab_interface.webp)

Ожидаем подключения и видим примерно такую картину:

![](.\images\02_colab_interface.webp)

Следующим шагом мы идем в верхнее меню и выбираем *Runtime - Change runtime type*:

![](.\images\03_colab_interface.webp)

В открывшемся окне настроек ноутбука выбираем *Python 3*, а в качестве ускорителя указываем *GPU*, т.е. графическую карту и нажимаем *Save*.

![](.\images\04_colab_interface.webp)

И, наконец, последний момент. Если мы работаем с уже готовым ноутбуком и хотим иметь возможность его править, нам нужно сохранить себе его копию, поэтому выбираем в верхнем меню *«File – Save a copy to Drive…»*

![](.\images\05_colab_interface.webp)

В результате этого действия копия этого файла сохранится на ваш *Google Drive* и автоматически откроется в соседней вкладке.



#### Обучающий набор данных

В качестве обучающего набора рукописные цифр, воспользуемся набором данных MNIST. Это специальный набор данных, в котором собрано большое количество изображений рукописных цифр от 0 до 9.

> Ранее она активно использовалась почтой США при распознавании цифр почтовых индексов, а сейчас она очень часто применяется именно в демонстрационных целях, чтобы показать, как работают несложные нейронные сети.

Подробнее про датасет MNIST можно посмотреть [тут](https://vbystricky.github.io/2017/10/mnist_cnn.html).



#### Подготовка 

Первым делом подключаем необходимые библиотеки:

```python
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import utils
from tensorflow.keras.preprocessing import image
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
from scipy.misc import toimage
%matplotlib inline 
```

В первой строке мы импортируем предустановленный датасет MNIST с изображениями рукописных цифр, которые мы будем распознавать.

Затем мы подключаем библиотеки Sequential и Dense т.к. работаем с полносвязной сетью прямого распространения.

Наконец, мы импортируем дополнительные библиотеки, позволяющие нам работать с данными (NumPy, Matplotlib и др.).

Сразу обратите внимание на модульную структуру ноутбука, благодаря которой вы можете в любом порядке чередовать блоки кода и текстовые поля.

Для того, чтобы добавить новую ячейку кода, текстовое поле или поменять порядок их следования воспользуйтесь, кнопками CODE, TEXT и CELL прямо под основным меню.

![](.\images\07_colab_interface.webp)

Для того, чтобы добавить комментарий непосредственно к ячейке, сослаться на нее, добавить форму или удалить её, нажмите на три точки в верхней правой части любой ячейки и увидите соответствующее меню.

![](.\images\08_colab_interface.webp)

Для запуска фрагмента кода нам нужно просто нажать на значок *play* слева вверху от кода. Он появляется при выделении блока с кодом, либо при наведении мышки на пустые квадратные скобки, если блок не выделен.



#### Подготовка данных для обучения сети

Следующим шагом с помощью функции `load_data` мы подгружаем данные, необходимые для обучения сети, где `x_train_org` и `y_train_org` – данные обучающей выборки, а `x_test_org` и `y_test_org` – данные тестовой выборки.

Их названий выборок понятно, что обучающую выборку мы используем для того, чтобы обучить сеть, в то время как тестовая используется для того, чтобы проверить, насколько качественно произошло это обучение.

Смысл тестовой выборки в том, чтобы проверить, насколько точно отработает наша сеть с данными, с которыми она не сталкивалась ранее. Именно это является самой важной метрикой оценки сети.

![](.\images\09_colab_interface.webp)

В `x_train_org` находятся сами изображения цифр, на которых обучается сеть, а `y_train_org` – правильные ответы, какая именно цифра изображена на том или ином изображении.

> Сразу важно отметить, что формат представления правильных ответов на выходе из сети - одномерный массив (вектор), хранящий 10 цифр – 0 или 1. При этом положение единицы в этом векторе и говорит нам о верном ответе.
>
> Например, если цифра на картинке изображен 0, то вектор будет выглядеть как в первой строке на картинке ниже.
>
> Если на изображении цифра 2, то единица в векторе будет стоять в 3 позиции (как в строке 2).
>
> Если же на изображении цифра 9, то единица в векторе будет стоять в последней, десятой позиции.
>
> Это объясняется тем, что нумерация в массивах по умолчанию начинается с нуля.

```python
# 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
# 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
# 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
```

Для проверки, корректно ли загрузились данные, мы можем произвольно указать номер элемента массива с цифрами и посмотреть его содержимое:

![](.\images\010_colab_interface.png)

После запуска этого кода мы увидим цифру 3.

![](.\images\011_colab_interface.png)

Далее мы производим преобразование размерности данных в обучающем наборе картинок – это необходимо для корректной работы с ними в дальнейшем.

![](.\images\012_colab_interface.webp)

Изначально на вход сети в обучающей выборке подается 60 тыс. изображений размером 28 на 28 пикселей. В тестовой выборке таких изображений 10 тыс. штук. Наша задача - привести их к одномерному массиву (вектору), размерность которого будет не 28 на 28, а 1 на 784, что мы и делаем в коде выше.

Следующий наш шаг – это так называемая нормализация данных, их "выравнивание" с целью привести их значения к диапазону от 0 до 1. Дело в том, что до нормализации изображение каждой рукописной цифры (все они представлены в градациях серого) представлено числами от 0 до 255, где 0 представляет собой чёрный цвет, а 255 — белый). Однако для эффективной работы сети нам необходимо привести их к другому диапазону, что мы и делаем, разделив каждое значение на 255.

![](.\images\013_colab_interface.webp)

Теперь давайте убедимся в том, что в массиве ответов находятся верные ответы. Для этого мы можем запустить код ниже и убедиться, что в указанном нами выше элементе массива 157 действительно хранится ответ, что это цифра 3:

![](.\images\014_colab_interface.webp)

Следующий шаг – это преобразование массива правильных ответов в формат про который мы уже упоминали выше.

![](.\images\015_colab_interface.webp)

Производит это преобразование функция `to_categorical`, которая трансформирует цифры от нуля до девяти в вектор из десяти цифр, в результате чего наш правильный ответ 3 будет теперь выводиться в ином виде:

![](.\images\016_colab_interface.webp)

Единица в четвертой позиции этого массива как раз обозначает цифру 3.



#### Создание нейронной сети

На этом сбор данных и их простая предобработка завершены. Дальше нам нужно будет создать нейронную сеть и задать её архитектуру. В нашем случае мы создадим последовательную сеть прямого распространения, пример которой мы рассматривали самым первым, когда говорили про типы архитектур.

![](.\images\017_colab_interface.webp)

Далее мы указываем слои, которые будут использоваться в данной сети, создаем её архитектуру:

![](.\images\45.webp)

Мы добавляем в качестве входного полносвязный слой из 800 нейронов, на вход каждого из которых приходят все 784 значения интенсивности пикселов (это размерность вектора, в который мы преобразовали исходные квадратные картинки) и используем активационную функцию *ReLU*.

![](.\images\018_colab_interface.webp)

В данном случае количество нейронов (800) уже подобрано эмпирически. При таком количестве нейронная сеть обучается лучше всего (безусловно, на старте своих исследований мы можем пробовать самые разные варианты, постепенно приходя к оптимальному).

В качестве выходного слоя у нас будет полносвязный слой из 10 нейронов – по количеству рукописных цифр, которые мы распознаём.

И наконец, функция `softmax` будет преобразовывать вектор из 10 значений в другой вектор, в котором каждая координата представлена вещественным числом в интервале [0,1] и сумма этих координат равна 1. Эта функция применяется в машинном обучении для задач классификации, когда количество классов больше двух, при этом полученные координаты трактуются как вероятности того, что объект принадлежит к определенному классу.

После этого мы компилируем сеть и выходим на экран ее архитектуру.

![](.\images\019_colab_interface.webp)



#### Обучение нейронной сети

Для обработки ошибок мы используем функцию `categorical_crossentropy` - её лучше использовать, когда у нас на выходе происходит классификация объектов, а диапазон значений составляет от 0 до 1.

В качестве оптимизатора используем `adam`, который похож по своей сути на метод обратного распространения ошибки, но с некоторой инерцией, а метрикой оценки качества обучения сети у нас служит точность – `accuracy`.

После этого мы запускаем обучение сети с помощью метода `fit`:

![](.\images\020_colab_interface.webp)

В качестве параметров мы передаем ему данные обучающей выборки – сами картинки и правильные ответы. Также мы устанавливаем значения для:

- `batch_size=200` - количество картинок, с которыми идет работа в пределах одной итерации до изменения весов,
- `epochs=20` - количество повторений циклов обучения для всей выборки из 60 тыс. картинок,
- `verbose=1` - определение того, какой объем служебной информации о процессе обучения мы увидим (см. картинку ниже)

На скриншоте мы можем видеть, как последовательно сменяются эпохи обучения, продолжительностью по 2 с лишним секунды, количество обработанных изображений (везде по 60 тыс.), а также значения ошибки (`loss`) и точности распознавания изображений (`acc`) по итогам каждой эпохи.



#### Анализ результатов обучения

Мы видим, что значение ошибки по итогам 20 эпох составило 0,0041, а точность - 0,9987, вплотную приблизившись к 100%.

![](.\images\021_colab_interface.webp)

Обратите внимание, что `batch_size` и количество эпох мы подбираем экспериментально в зависимости от текущей задачи, архитектуры сети и входных данных.



#### Сохранение обученной нейронной сети

Когда наша сеть обучится, мы можем сохранить её себе на компьютер с помощью метода `save`:

![](.\images\022_colab_interface.webp)

Сначала мы записываем сеть в файл, затем можем проверить, что он сохранился, после чего сохраняем файл на компьютер с помощью метода `download`.



#### Использование сети для распознавания рукописных цифр

Проверим, как наша сеть распознает рукописные цифры, которые она еще не видела. Для этого нам понадобится тестовая выборка, которая, наряду с обучающей, также входит в датасет MNIST.

Для начала выберем произвольную цифру из набора тестовых данных и выведем её на экран:

![](.\images\023_colab_interface.png)

![](.\images\024_colab_interface.webp)

Увидев, какую цифру нам должна распознать нейронная сеть, подготовимся к ее распознаванию через изменение размерности изображения и его нормализацию:

![](.\images\025_colab_interface.png)

После чего запускаем сам процесс распознавания с помощью метода `predict` и смотрим на полученный результат:

![](.\images\026_colab_interface.webp)

Мы видим результат в уже знакомом нам формате и понимаем, что цифра 2 была распознана нейронной сетью верно.

Если мы хотим привести её к обычному виду, мы можем вывести на экран итоговый ответ в более понятном виде благодаря использованию функции `argmax`, преобразующей наибольшее значение (в нашем случае единицу) в искомое число, исходя из его позиции в векторе.

![](.\images\027_colab_interface.webp)

В первом случае мы распечатали результат работы метода `predict` и получили значение 2.

Во втором блоке кода мы напрямую распечатали искомый элемент из массива `y_test_org` по его индексу, получив значение 2. Таким образом, мы делаем вывод, что сеть распознала данное изображение верно.



#### Самостоятельное исследование

Теперь, когда мы получили некие первичные результаты, мы можем продолжить процесс исследования, меняя различные параметры нашей нейронной сети. Например, мы можем поменять количество нейронов во входном слое и уменьшить их количество с 800, например, до 10.

Для того, чтобы запустить сеть обучаться повторно после внесенных изменений с нуля, нам необходимо заново пересобрать модель, запустить код с измененными параметрами сети и снова её скомпилировать (в противном случае сеть будет дообучаться, что требуется далеко не всегда).

Для этого мы просто заново нажимаем на *play* последовательно во всех трех блоках кода (см. ниже). В результате этих действий вы увидите, что исходные данные изменились, и сеть теперь имеет 2 слоя по 10 нейронов, вместо 800 и 10, которые были ранее.

![](.\images\028_colab_interface.webp)

После этого мы можем запустить сеть обучаться повторно и получим иные результаты. Например:

![](.\images\029_colab_interface.webp)

Здесь мы видим, что за те же 20 эпох сеть смогла достичь точности 93,93%, что значительно ниже, чем в предыдущем случае.

Продолжив исследование дальше, мы можем добавить в архитектуру сети еще один слой, допустим также из 10 нейронов и вставить его между уже имеющимися слоями. Таким образом мы создадим скрытый слой и потенциально можем улучшить качество работы сети:

![](.\images\030_colab_interface.webp)

Мы добавили еще один слой из 10 нейронов, который будет связан с предыдущим слоем также из 10 нейронов. Поэтому значение `input_dim` мы установили равным 10 (это опционально, нейронная сеть сработает корректно и без специального указания этого числа).

Теперь по итогам обучения сети мы приходим к следующим значениям:

![](.\images\031_colab_interface.webp)

Мы видим точность в 93,95%, т.е. практически идентичную той, что была в предыдущем варианте сети (93,93%), поэтому можем сделать вывод, что это изменение архитектуры практически не повлияло на качество распознавания.

И, наконец, давайте проведем еще один эксперимент, сделав так, чтобы все 784 значения приходили на один единственный нейрон входного слоя:

![](.\images\032_colab_interface.png)

Запускаем обучение и смотрим на результат.

![](.\images\033_colab_interface.png)

Как мы видим, даже при одном нейроне в скрытом слое сеть достигла точности почти в 38%. Понятно, что с таким результатом она едва ли найдет практическое применение, однако мы делаем это просто для понимания того, как могут разниться результаты при изменении архитектуры.

Итак, завершая разбор кода, следует сделать важную оговорку: то, что мы смотрим точность на обучающей выборке – это просто пример для понимания того, как это работает. В действительности, качество работы сети нужно замерять исключительно на тестовой выборке с данными, с которыми нейронная сеть еще не сталкивалась ранее.

И теперь, когда мы немного поэкспериментировали, давайте подведем небольшой итог и посмотрим, как подойти к проведению экспериментов с нейронными сетями системно, чтобы получать действительно статистически значимые результаты.

Итак, мы берем одну модель сети, и в цикле формируем из имеющихся данных 100 разных обучающих и тестовых выборок в пропорции 80% - обучающая выборка, и 20% - тестовая. Далее на всех этих данных мы проводим 100 обучений нейронной сети со случайной точки (каждый раз сеть стартует со случайными весами) и получаем некую ошибку на тестовой выборке - среднюю за эти 100 обучений на данной конкретной архитектуре (но с разными комбинациями обучающей и тестовой выборок).

Потом берется другая архитектура и делается то же самое. Таким образом мы можем проверить, например несколько десятков вариантов архитектур по 100 обучений на каждой, в результате чего получим статистически значимые результаты своих экспериментов и сможем выбрать самую точную сеть.



### Запуск нейронной сети на компьютере - на примере распознания цветов

ВНИМАНИЕ - ДАННЫЙ БЛОК МОЖЕТ БЫТЬ НЕВЫПОЛНЕН, ТАК КАК НЕ ВСЕ КОМПЬЮТЕРЫ ПОДЕРЖИВАЮТ РАБОТУ С БИБЛИОТЕКОЙ *TENSORFLOW*.

Настроим и обучим нейросеть распознавать картинки и говорить, какой цветок мы ей показываем — розу, тюльпан или что-то другое. Мы используем цветы, потому что скачали уже готовый, собранный и размеченный набор фотографий, на котором нейросеть может научиться. 

> Если вы хотите, чтобы она научилась распознавать на фото вас или ваших друзей, нужно будет собрать другой датасет и переобучить нейросеть.

Понадобится *Python* версии *3.8* и выше, обязательно под архитектуру *x64*. Если взять *32*-разрядную версию, то нужная в проекте библиотека *Tensorflow*  работать не будет. Мы используем версию [*3.9.7*](https://www.python.org/downloads/release/python-397/). Инструкция по [установке Python](https://thecode.media/py-install/). 

Все команды, которые есть в проекте, мы будем запускать в командной строке. Чтобы не было ошибок, лучше всего запустить её от имени администратора (в *Windows*) или с правами суперпользователя root (в *Mac OS* и *Linux*).

Весь код проекта можно посмотреть [тут](https://github.com/mlnchkdv/mlnchkdv.github.io/tree/main/dl2022.1/4_running/flower_classifier).



#### Создаём виртуальное окружение

Чтобы не раскидывать файлы, скрипты и картинки по всему компьютеру, создадим в питоне виртуальное окружение — специальный проект, который хранит все данные внутри своей папки. Он не мешает остальным проектам и не влияет на работу других программ, а также позволяет разворачивать проект на любом другом компьютере, где есть *Python*. Подробнее про *Virtual Environments* встроенный в *Puthon* и запуск файла [requirements.txt](./flower_classifier/requirements.txt) смотри в [инструкции](https://python.ivan-shamaev.ru/python-virtual-env-packages-virtualenv-venv-requirements-txt/).

Чтобы создать виртуальное окружение, в терминале перейдите в папку проекта и запустите команду:

```bash
python -m venv venv
```

В результате, в папке проекта будет создана папка **venv** с содержимым:

![](.\images\python_venv_env.jpg)

Далее необходимо активировать виртуальную среду, введя команду:

```bash
.\venv\Scripts\Activate.ps1
```

Префикс вашего рабочего каталога изменится на venv. Теперь пока ваша виртуальная среда активирована, **pip будет устанавливать пакеты в эту конкретную среду**, и вы сможете импортировать и использовать пакеты в своем приложении Python.

Теперь можно устанавливать пакеты в нашу виртуальную среду. Вы можете устанавливать каждый пакет по отдельности, вводя команду:

```bash
pip install pandas
```

Так вы получите последнюю версию пакеты, но можно указывать конкретную версию пакета, чтобы не столкнуться с несовместимостью некоторых новых функций:

```bash
pip install pandas==0.25.0
```

Для удобства, можно заранее вынести весь список необходимых библиотек в отдельный файл [requirements.txt](./flower_classifier/requirements.txt) и установить пакеты сразу все из этого списка, сохраним данный файл в корне проекта и запустим:

```bash
pip install -r requirements.txt
```

Последняя операция может занять некоторое время. После чего у вас в виртуальном окружении будут установлены все необходимые пакеты для дальнейшей работы.

![](.\images\consoleVSC.png)

> `tensorflow` - 280 МБ, `pandas` - 10 МБ, `numpy` - 14 МБ и небольшие зависимые библиотеки будут загружены и установлены автоматически. 



#### Установка *Tensorflow* 

На случай проблем с автоматической установкой *Tensorflow*, рассмотрим этап отдельной установки. Для установки пишем команду:

```bash
pip install tensorflow
```

Если на вашем компьютере установлен GPU и вы хотите задействовать его, то необходимо отменить установку пакета `tensorflow` и установить вместо него пакет `tensorflow-gpu`:

```bash
pip uninstall tensorflow
pip install tensorflow-gpu
```

Также может потребоваться установить совместимую библиотеку GPU.

Чтобы убедиться, что библиотека установилась правильно и работает штатно, проверим её простым тестом. Пишем команду:

```
python
```

Начало командной строки поменялось на `>>>` — это значит, что питон готов к приёму команд. Пишем по очереди:

```python
hello = tf.constant('Hello, TensorFlow')
sess = tf.compat.v1.Session()
print(sess.run(hello))
```

Если в консоли распечаталось 'Hello, TensorFlow', это значит, что всё работает правильно.



#### Устанавка классификатора

Задача классификатора — научить нейросеть понимать, чем одни цветы отличаются от других. Если бы мы вместо цветов использовали фото зданий, нейронка бы научилась отличать барокко от роккоко и неоклассицизма.

У *Tensorflow* есть уже предобученный классификатор и готовые учебные проекты показывающие разные возможности библиотеки. Воспользуемся одним из таких проектов.

1. [Качаем архив с классификатором](https://github.com/googlecodelabs/tensorflow-for-poets-2/archive/refs/heads/master.zip)(28 МБ).
2. Распаковываем архив.

![](.\images\image6-1-1920x454.png)

3. Копируем содержимое архива в папку вашего проекта.



#### Загрузка фотографий для обучения

Скачиваем уже собранный [датасет с цветами](https://drive.google.com/file/d/1_RO4G5D6luaBGvWeQdStPeK426cMrNZk/view?usp=sharing)(218 МБ), распаковываем его и копируем в папку вашего проекта.



#### Адаптация скриптов под актуальную версию *Tensorflow*

На текущий момент актуальная версия *tensorflow* — 2.8. Но скрипты и алгоритмы, которые мы используем, были написаны под старую версию, поэтому необходимо их адаптировать под новую версию.

1. Переходим в каталог вашего проекта в папку `/scripts` и находим файл `retrain.py`.

2. Открываем его в любом редакторе кода.

3. Нажимаем `Ctrl + H` или `Command + H` — включится режим поиска и автозамены текста.

4. Первая строка (что заменить) → пишем `tf. `(с точкой).

5. Вторая строка (на что заменить) → пишем `tf.compat.v1.` (тоже с точкой в конце).

6. Нажимаем `Replace All` (Заменить всё).

7. То же самое делаем в файле `label-image.py`.

8. В том же файле `label-image.py` добавляем после строки 25 «`import tensorflow as tf`» такую строку:

   ```python
   tf.compat.v1.disable_eager_execution ()
   ```

Благодаря действиям выше мы сможем запустить написанный под старую версию скрипт работать с новой версией.

![](.\images\retrain.png)



#### Обучение нейронной сети

1. В командной строке командой `cd` переходим в папку вашего проекта.

2. Запускаем команду:

   ```bash
   python scripts/retrain.py --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir=flower_photos
   ```


Пошёл процесс обучения. В нём 4000 этапов, по времени занимает примерно 20 минут. За это время нейросеть обработает около 250 фото (это очень мало для нейросети) и научится отличать розу от ландышей:

![](.\images\image10-1920x771.png)



#### Запуск нейронной сети

Чтобы проверить работу нашей нейросети, скачиваем [любой файл с розой](https://i.pinimg.com/originals/b9/15/f0/b915f0e7361a1d1bb618c422a09f8451.jpg) из интернета, кладём его в папку проекта и пишем такую команду:

```bash
python scripts/label_image.py --image image.jpg
```

Нейросеть думает, а потом выдаёт ответ в виде процентов. В нашем случае она на 98% уверена, что это роза:

![](.\images\image5-1-1920x922.png)

А вот как нейросеть реагирует [на фото Цукерберга](https://www.kino-teatr.ru/news/9883/97057.jpg):

![](.\images\image1-2-1920x395.png)

50% — что на фото тюльпан, и на 18% — что это одуванчик. А всё потому, что она умеет различать только 5 видов цветов, а не лица.


