# [⬅Глубокое обучение 2022.1](../index.html)

## Модель нейронной сети

[TOC]

![](.\images\network.png)

Под термином **сеть** понимается искусственная нейронная сеть, представляющая собой **стек взаимосвязанных слоёв**, где структурно-функциональной **единицей является узел или нейрон**. Исходные данные подаются на вход сети, а на её выходе мы получаем преобразованные данные. Каждый слой выполняет определенную математическую операцию над пропускаемыми через него данными и характеризуется набором переменных, изменение которых определяет точное поведение слоя. Здесь термин данные означает тензор — вектор, имеющий несколько измерений. Так тензоры нулевого ранга — скаляры, тензоры первого ранга — векторы, тензоры второго ранга — матрицы, тензоры третьего — матрицы в массиве, так называемый числовой куб и так далее для тензоров высших рангов.

> В глубоком обучении чаще всего используются тензоры от нулевого ранга до четырехмерных, но иногда, например при обработке видеоданных, дело может дойти  до пятимерных тензоров.

![](.\images\EOWNQ_iXsAEQq5x.jpg)

С точки зрения структурно-функциональной единицы слоя, т.е. **нейрона**, он **принимает один или несколько входов**, **умножает каждый вход на** параметр, так называемый **вес**, **суммирует** взвешенные входные значения между собой с некоторыми значением смещения (***bias***) (обычно 1), а затем **передает значение в активационную функцию**. Этот результат затем направляется дальше, к другим нейронам в следующих слоях, расположенным глубже в нейронной сети, если они существуют.

![](.\images\perceptron.png)

Как видно из схемы одной из первых моделей нейрона (перцептрон) — это линейная модель бинарной классификации.



### Перцептрон

В конце 1950-х годов американский нейробиолог Фрэнк Розенблатт (*Frank Rosenblatt*) опубликовал статью о алгоритме моделирующем, в его понимании биологические нейроны, названных в последствии  **линейным перцептроном** или просто **перцептроном** (в некоторых русских источниках, можно также встретить вариант: **персептрон**), что можно считать одной из первых реализаций искусственного нейрона. 

> Предшественником перцептрона был блок пороговой логики (БПЛ), разработанный Маккалоком и Питтсом в 1943 году и способный обучаться логическим функциям И и ИЛИ. Алгоритм обучения перцептрона относится к алгоритмам обучения с учителем. В основе идеи как БПЛ, так и перцептрона лежал биологический нейрон. 
>
> Также Маккалок и Питтс ввели в обиход важную идею анализа нейронной активности, основанную на пороговых значениях и взвешенных суммах. Эти идеи легли в основу разработки модели для более поздних вариантов, в т. ч. перцептрона.

Подобно своему биологическому аналогу, перцептрон может:

- *Принимать информацию* от множества других нейронов.
- *Агрегировать эту информацию* с использованием простой арифметической операции, которая называется взвешенной суммой.
- *Генерировать выходной сигнал*, если взвешенная сумма превысит пороговое значение, который затем может быть отправлен многим другим нейронам в сети.

По сути своей перцептрон Розенблатта — это линейная модель классификации, в которой он принимает и передаёт только двоичную информацию,  т.е. выполняет самую простую бинарную классификацию, когда все объекты в тренировочной выборке помечены одной из двух меток, и задача состоит в том, чтобы научиться расставлять эти метки у новых, ранее не неизвестных объектов. А «линейная модель» означает, что в результате обучения модель разделит все пространство входов на две части **гиперплоскостью**: правило принятия решения о том, какую метку ставить, будет **линейной функцией от входящих признаков**.

> В геометрии гиперплоскостью называется подпространство, размерность которого на единицу меньше размерности объемлющего пространства. В трехмерном случае размерность гиперплоскости равна 2, а в двумерном гиперплоскостью считается одномерная прямая.
>
> Гиперплоскость делит n-мерное пространство на две части и потому имеет полезные применения в приложениях классификации. Оптимизация параметров гиперплоскости – и есть ключевая идея линейного моделирования.

Если рассматривать перцептрон как «черный ящик» и говорить строгим математическим языком, то — это линейный бинарный классификатор со связью между входом и выходом. Внутри же можно выделить 2 этапа: в начале **вычисляется взвешенная сумму** из $n$ входов и далее **сумма передаётся ступенчатой функции** с заданным пороговым значением (***threshold***). Обычно в перцептронах применяется ступенчатая функция Хевисайда с порогом $0.5$. Эта функция возвращает число $0$ или $1$ в зависимости от входного аргумента.

> Сразу оговоримся, что решающая граница и результат классификации функцией Хевисайда описывается следующим образом:
> $$
> \theta = 
> \left\{\begin{matrix}
> 1 :& \sum > 0.5\\ 
> 0 :& \sum \leqslant 0.5
> \end{matrix}\right.
> $$
>
> - Если взвешенная сумма входных значений перцептрона превышает пороговое значение, выводится 1.
> - Если взвешенная сумма входных значений перцептрона меньше или
>   равна пороговому значению, выводится 0.
>
> Ниже мы рассмотрим её подробнее.

Обозначим входные значения (каждый вход) как вектор вещественных чисел $\mathbf{x}=\vec{x}=(x_1,..x_n) \in \mathbb{R}^n$, где $n$ — общее количество входов в перцептроне.

На этапе вычисления взвешенной сумму, перцептрон независимо взвешивает каждое из входных значений и суммирует. В общем виде **сумма всех взвешенных входных значений** записывается как:
$$
\sum_{i=1}^{n} x_i w_i
$$
Роль сумматора в данном случае очевидна: он преобразует все входные сигналы (которых может быть много) в одно число - взвешенную сумму, которая характеризует поступивший на нейрон сигнал в целом.

```python
import numpy as np

class Neuron:
	def __init__(self, w):
		self.w = w
    
    # Сумматор
	def у(self, х):
		s = np.dot(self.w, х) # Суммируем входы
		return s # функция активации

# Задание значений входам 
Xi = np.array( [2, 3])
# Веса входных сенсоров
Wi = np.array( [1, 1])
# Создание объекта из класса Neuron
n = Neuron (Wi)

print('S1 = ', n.y(Xi)) # Обращение к нейрону
Xi = np.array([S, 6]) # Веса входных сенсоров
print('S2 = ', n.y(Xi)) # Обращение к нейрону

```



Далее, на этапе сравнения взвешенной суммы входов с порогом нейрона, . 







### Функции активации

БОЛЬШЕ ПРО ОБЩИЙ СМЫСЛ

В общем смысле **функция активации** — требуется для того, что бы после вычисления суммы данных ***x\*** и коэффициентов ***w\*** подать на вход функции сумму N такую, что бы сумма **N ≥ порога (True)**. Если сумма **N < порога** — активация на выходе не произойдет (False).


$$
output = 
\left\{\begin{matrix}
0 :& \sum_i w_i x_i < threshold \\ 
1 :& \sum_i w_i x_i \geqslant threshold
\end{matrix}\right.
$$
Для упрощения, внесем небольшую корректировку в приведенную выше формулу. Переместим порог на другую сторону неравенства и заменим его на то, что известно как смещение нейрона. В результате, *смещение = - порог.*
$$
output = 
\left\{\begin{matrix}
0 :& \sum_i w_i x_i + bias < 0 \\ 
1 :& \sum_i w_i x_i + bias \geqslant 0
\end{matrix}\right.
$$
Поскольку значения весов и порога изначально расставляются случайным образом, то данное преобразование делается для того, чтобы при подборе «правильных» весов и порога для нашей сети, вносить изменения приходилось только в левую часть уравнения, в то время как правая часть остаётся постоянной и равняется нулю.





Ниже приведены только основные функции. На деле их достаточно много и все остальные на практике подгоняются под очень тонкие предметные области и задачи. Одной из самых популярных функций активации является сигмоида, в то время как функции Хевисайда и Гистерезиса больше применяются в обучающих целях.

![](.\images\f_act.png)

![](.\images\6f_act.png)

GEOGEBRA FULL VERSION

Про производную

> Что же выбрать и как оценить, какая функция активации лучше подходит для конкретной задачи?
>
> Во время разработки реальной системы глубокого обучения большинство сетей будет использовать одну из двух функций активации: либо логистический сигмоид $\sigma$, либо ReLU. С них, особенно ReLU, и рекомендуется начинать разработку, а потом уже, можно попробовать параметризованные ReLU и другие современные идеи: они могут дать некоторое улучшение качества, но оно, вероятнее всего, будет маргинальным, и эту оптимизацию лучше отложить на потом.
>
> Подбор функции активации это далеко не первый и не главный вопрос в разработке систем глубокого обучения, куда важнее выбрать правильную  архитектуру системы и алгоритмы оптимизации.



#### Пороговая функция или функция Хевисайда

![](.\images\Heaviside.svg)

Пороговая (ступенчатая) функция или функции единичного скачка или функция Хевисайда 

Как было рассмотрено выше, если входное значение меньше порогового, то значение функции активации равно минимальному допустимому, иначе — максимально допустимому.

![](.\images\0-92154-168992.png)

Математическая модель: 
$$
step(h) = f(h) = 
\left\{\begin{matrix}
0 :& h < threshold \\ 
1 :& h \geqslant threshold
\end{matrix}\right.
$$
или
$$
H\left(t\right)=\left\{t<0\ :\ 0,\ t\ge0\ :\ 1\right\}
$$




```python
def Heaviside(x):
    if x >= 0.5:
        return 1
    else:
    	return 0
```

DESMOS



#### Функция Гистерезис или линейный порог



```python
def Linear_foo(x):
	f = math.pow(x, 2) / 2
    return f
```



#### Сигмоид или логистическая функция

![](.\images\sigmoid.png)


$$
sig(x) = \sigma(x) = \frac{1}{1 + e^{-x}}
$$


```python
def Sigmoid_foo(x):
    if x >= 0.5:
        z = np.exp(-x)
        return 1 / (1 + z)
    else: 
        z = np.exp(x)
        return z / (1 + z)
```

https://www.geogebra.org/m/VYbEccc9



#### Гиперболический тангенс (tanh)


$$
\tanh(x) = \frac{\sinh(x)}{\cosh(x)} = \frac{e^x - e^{-x}}{e^x + e^{-x}} = \frac{e^{2x} - 1}{e^{2x} + 1}
$$




```python
def Hyperbolistic_Th(x):
    Tn = (np.exp(2*x) - 1) / (np.exp(2*x) + 1)
    return Th
```



#### Линейная ректификация (*ReLU*)

Линейная ректификация (*rectified linear units - ReLU*) или спрямленная линейная единичная функция









### Общая модель нейрона и нейронной сети

![](.\images\neuron.png)

модель (искусственного) нейрона



### Типы нейронных сетей

Простейший 



#### Полносвязные сети

#### Сверточные сети

![](.\images\CNN.png)





#### Рекуррентные сети

#### Состязательные сети и автокодировщики





### Выводы

Существует множество способов построения сетей. Конкретный выбор, определяется стоящими перед сетью задачами. Проектирование новых типов сетей относится к области научных исследований, и даже реализация сети, архитектура которой описана в литературе, — тяжелая задача. На практике проще всего взять готовый образец, делающий нечто концептуально схожее, и постепенно, шаг за шагом, вносить в него изменения, пока не получится то, что вам нужно.



### Тест





---

### Источники





### Дополнительные материалы

