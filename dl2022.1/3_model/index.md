# [⬅Глубокое обучение 2022.1](../index.html)

## Модель нейронной сети

[TOC]

![](.\images\network.png)

Под термином **сеть** понимается искусственная нейронная сеть, представляющая собой **стек взаимосвязанных слоёв**, где структурно-функциональной **единицей является узел или нейрон**. Исходные данные подаются на вход сети, а на её выходе мы получаем преобразованные данные. Каждый слой выполняет определенную математическую операцию над пропускаемыми через него данными и характеризуется набором переменных, изменение которых определяет точное поведение слоя. Здесь термин данные означает тензор — вектор, имеющий несколько измерений. Так тензоры нулевого ранга — скаляры, тензоры первого ранга — векторы, тензоры второго ранга — матрицы, тензоры третьего — матрицы в массиве, так называемый числовой куб и так далее для тензоров высших рангов.

> В глубоком обучении чаще всего используются тензоры от нулевого ранга до четырехмерных, но иногда, например при обработке видеоданных, дело может дойти  до пятимерных тензоров.

![](.\images\EOWNQ_iXsAEQq5x.jpg)

С точки зрения структурно-функциональной единицы слоя, т.е. **нейрона**, он **принимает один или несколько входов**, **умножает каждый вход на** параметр, так называемый **вес**, **суммирует** взвешенные входные значения между собой с некоторыми значением смещения (обычно 1), а затем **передает значение в активационную функцию**. Этот результат затем направляется дальше, к другим нейронам в следующих слоях, расположенным глубже в нейронной сети, если они существуют.

![](.\images\perceptron.png)

Как видно из схемы одной из первых моделей нейрона (перцептрон) — это линейная модель бинарной классификации.



### Перцептрон

В конце 1950-х годов американский нейробиолог Фрэнк Розенблатт (*Frank Rosenblatt*) опубликовал статью о алгоритме моделирующем, в его понимании биологические нейроны, названных в последствии  **линейным перцептроном** или просто **перцептроном** (в некоторых русских источниках, можно также встретить такой вариант, как **персептрон**), что можно считать одной из первых реализаций искусственного нейрона. 

> Предшественником перцептрона был блок пороговой логики (БПЛ), разработанный Маккалоком и Питтсом в 1943 году и способный обучаться логическим функциям И и ИЛИ. Алгоритм обучения перцептрона относится к алгоритмам обучения с учителем. В основе идеи как БПЛ, так и перцептрона лежал биологический нейрон. 
>
> Также Маккалок и Питтс ввели в обиход важную идею анализа нейронной активности, основанную на пороговых значениях и взвешенных суммах. Эти идеи легли в основу разработки модели для более поздних вариантов, в т. ч. перцептрона.

Подобно своему биологическому аналогу, перцептрон может:

- *Принимать информацию* от множества других нейронов.
- *Агрегировать эту информацию* с использованием простой арифметической операции, которая называется взвешенной суммой.
- *Генерировать выходной сигнал*, если взвешенная сумма превысит пороговое значение, который затем может быть отправлен многим другим нейронам в сети.

По сути своей перцептрон Розенблатта — это линейная модель классификации, в которой он принимает и передаёт только двоичную информацию,  т.е. выполняет самую простую бинарную классификацию, когда все объекты в тренировочной выборке помечены одной из двух меток, и задача состоит в том, чтобы научиться расставлять эти метки у новых, ранее не неизвестных объектов. А «линейная модель» означает, что в результате обучения модель разделит все пространство входов на две части гиперплоскостью: правило принятия решения о том, какую метку ставить, будет линейной функцией от входящих признаков.

> В геометрии гиперплоскостью называется подпространство, размерность которого на единицу меньше размерности объемлющего пространства. В трехмерном случае размерность гиперплоскости равна 2, а в двумерном гиперплоскостью считается одномерная прямая.
>
> Гиперплоскость делит n-мерное пространство на две части и потому имеет полезные применения в приложениях классификации. Оптимизация параметров гиперплоскости – и есть ключевая идея линейного моделирования.

Если рассматривать перцептрон как «черный ящик», то — это линейный бинарный классификатор с связью между входом и выходом. Внутри же можно выделить 2 этапа: в начале **вычисляется взвешенная сумму** из n входов и далее **сумма передаётся ступенчатой функции** с заданным пороговым значением. Обычно в перцептронах применяется ступенчатая функция Хевисайда с порогом 0.5. Эта функция возвращает число 0 или 1 в зависимости от входного аргумента.

Обозначим каждый вход как вектор вещественных чисел $\mathbf{x}=\vec{x}=(x_1,..x_n) \in \mathbb{R}^n$, где n — общее количество входов в нейрон.

На этапе вычисления взвешенной сумму, перцептрон независимо взвешивает каждое из входных значений. Сумма всех взвешенных входных значений:
$$
\sum_{i=1}^{n} x_i w_i
$$
Далее, на этапе сравнения взвешенной суммы входов с порогом нейрона, . 







### Функции активации





### Общая модель нейрона и нейронной сети

![](.\images\neuron.png)





### Типы нейронных сетей

Простейший 



#### Полносвязные сети

#### Сверточные сети

![](.\images\CNN.png)





#### Рекуррентные сети

#### Состязательные сети и автокодировщики





### Выводы

Существует множество способов построения сетей. Конкретный выбор, определяется стоящими перед сетью задачами. Проектирование новых типов сетей относится к области научных исследований, и даже реализация сети, архитектура которой описана в литературе, — тяжелая задача. На практике проще всего взять готовый образец, делающий нечто концептуально схожее, и постепенно, шаг за шагом, вносить в него изменения, пока не получится то, что вам нужно.



### Тест





---

### Источники





### Дополнительные материалы

